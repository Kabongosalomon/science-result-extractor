section: title
Faithful to the Original: Fact Aware Neural Abstractive Summarization
section: abstract
Unlike extractive summarization, abstractive summarization has to fuse different parts of the source text, which inclines to create fake facts. Our preliminary study reveals nearly 30% of the outputs from a state-of-the-art neural summarization system suffer from this problem. While previous abstractive summarization approaches usually focus on the improvement of informativeness, we argue that faithfulness is also a vital prerequisite fora practical abstractive summarization system. To avoid generating fake facts in a summary, we leverage open information extraction and dependency parse technologies to extract actual fact descriptions from the source text. The dual-attention sequence-to-sequence framework is then proposed to force the generation conditioned on both the source text and the extracted fact descriptions. Experiments on the Gigaword benchmark dataset demonstrate that our model can greatly reduce fake summaries by 80%. Notably , the fact descriptions also bring significant improvement on informativeness since they often condense the meaning of the source text.
section: Introduction
The exponentially growing online information has necessitated the development of effective automatic summarization systems. In this paper, we focus on an increasingly intriguing task, i.e., abstractive sentence summarization (Rush, Chopra, and Weston 2015a) which generates a shorter version of a given sentence while attempting to preserve its original meaning. This task is different from documentlevel summarization since it is hard to apply the common extractive techniques. Selecting existing sentences to form the sentence summary is impossible. Early studies on sentence summarization involve handcrafted rules (), syntactic tree pruning ( and statistical machine translation techniques. Recently, the application of the attentional sequence-tosequence (s2s) framework has attracted growing attention in this area (Rush, Chopra, and Weston 2015a; Source the repatriation of at least #,### bosnian moslems was postponed friday after the unhcr pulled out of the first joint scheme to return refugees to their homes in northwest bosnia . Target repatriation of bosnian moslems postponed s2s
bosnian moslems postponed after unhcr pulled out of bosnia: An example of fake summaries generated by the state-of-the-art s2s model. "#" stands fora digit masked during preprocessing.
As we know, sentence summarization inevitably needs to fuse different parts in the source sentence and is abstractive. Consequently, the generated summaries often mismatch with the original relations and yield fake facts. Our preliminary study reveals that nearly 30% of the outputs from a state-of-the-art s2s system suffer from this problem. Previous researches are usually devoted to increasing summary informativeness. However, one of the most essential prerequisites fora practical abstractive summarization system is that the generated summaries must accord with the facts expressed in the source. We refer to this aspect as summary faithfulness in this paper. A fake summary may greatly misguide the comprehension of the original text. Look at an illustrative example of the generation result using the state-of-the-art s2s model () in. The actual subject of the verb "postponed" is "repatriation". Nevertheless, probably because the entity "bosnian moslems" is closer to "postponed" in the source sentence, the summarization system wrongly regards "bosnian moslems" as the subject and counterfeits a fact "bosnian moslems postponed". Meanwhile, the s2s system generates another fake fact: "unhcr pulled out of bosnia" and puts it into the summary. Consequently, although the informativeness (ROUGE-1 F1=0.57) and readability of this summary are high, its meaning departs far from the original. This sort of summaries is nearly useless in practice.
Since the fact fabrication is a serious problem, intuitively, encoding existing facts into the summarization system should bean ideal solution to avoid fake generation. To achieve this goal, the first step is to extract the facts from the source sentence. In the relatively mature task of Open Information Extraction (OpenIE) (), a fact is usually represented by a relation triple consisting of (subject; predicate; object). For example, given the source sentence in, the popular OpenIE tool (Angeli, Premkumar, and Manning 2015) generates two relation triples including (repatriation; was postponed; friday) and (unhcr; pulled out of; first joint scheme). Obviously, these triples can help rectify the mistakes made by the s2s model. However, the relation triples are not always extractable, e.g., from the imperative sentences. Hence, we further adopt a dependency parser and supplement with the (subject; predicate) and (predicate; object) tuples identified from the parse tree of the sentence. This is also inspired by the work of parse tree based sentence compression (e.g.,). We represent a fact through merging words in a triple or tuples to form a short sentence, defined as a fact description. Fact descriptions actually form the skeletons of sentences. Thus we incorporate them as an additional input source text in our model. Our experiments reveal that the words in the extracted fact descriptions are 40% more likely to be included in the actual summaries than the entire words in the source sentences. That is, fact descriptions clearly provide the right guidance for summarization. Next, using both source sentence and fact descriptions as input, we extend the state-of-the-art attentional s2s model () to fully leverage their information. Specially, we use two Recurrent Neural Network (RNN) encoders to read the sentence and fact descriptions in parallel. With respective attention mechanisms, our model computes the sentence and fact context vectors. It then merges the two vectors according to their relative reliabilities. Finally, a RNN decoder makes use of the integrated context to generate the summary wordby-word. Since our summarization system encodes facts to enhance faithfulness, we call it FTSum.
To verify the effectiveness of FTSum, we conduct extensive experiments on the Gigaword sentence summarization benchmark dataset. The results show that our model greatly reduces the fake summaries by 80% compared to the state-of-the-art s2s framework. Due to the compression nature of fact descriptions, the use of them also brings the significant improvement in terms of automatic informativeness evaluation. The contributions of our work can be summarized as follows:
• To the best of our knowledge, we are the first to explore the faithfulness problem of abstractive summarization.
• We propose a dual-attention s2s model to push the generation to follow the original facts.
• Since the fact descriptions often condense the meaning of the source sentence, they also bring the significant benefit to promote informativeness.
section: Fact Description Extraction
Based on our observation, 30% of summaries generated by state-of-the-art s2s models suffer from fact fabrication, such as the mismatch between the predicate and its subject or object. Therefore, we propose to explicitly encode existing fact descriptions into the model. We leverage popular tools of Open Information Extraction (OpenIE) and dependency Sentence I saw a cat sitting on the desk Triples (I; saw; cat) (I; saw; cat sitting) (I; saw; cat sitting on desk). As we can see, OpenIE may extract multiple triples to reflect an identical fact in different granularities. In some extreme cases, one relation can yield over 50 triple variants, which brings high redundancy and burdens the computation cost of the model. To balance redundancy and fact completeness, we remove a relation triple if all its words are covered by another one. For example, only the last fact description (i.e., I saw cat sitting on desk) in is reserved. When different fact descriptions are extracted at the end, we use a special separator "|||" to concatenate them to accelerate the encoding process, which is explained by Eq. 2 and 3. OpenIE is able to give a complete description of the entity relations. However, it is worth noting that, the relation triples are not always extractable, e.g., from the imperative sentences. In fact, about 15% of the OpenIE outputs are empty on our dataset. These empty instances are likely to damage the robustness of our model. As observed, although the complete relation triples are not always available, the (subject; predicate) or (predicate; object) tuples are almost present in each sentence. Therefore, we leverage the dependency parser to dig out the appropriate tuples to supplement the fact descriptions. A dependency parser converts a sentence into the labeled (governor; dependent) tuples. We extract the predicate-related tuples according to the labels: nsubj, nsubjpass, csubj, csubjpass and dobj. To acquire more complete fact descriptions, we also reserve the important modifiers including the adjectival (amod), numeric (nummod) and noun compound (compound). We then merge the tuples containing the same words, and order words based on the original sentence to form the fact descriptions. Take the dependency tree in as an example. The output of OpenIE is empty for this sentence. Based on the dependency parser, we firstly filter the following predicate-related tuples: (prices; opened) (opened; tuesday) (dealers; said) and the modify-head tuples: (taiwan; price) (share; price) (lower; tuesday). These tuples are then merged to form two fact descriptions: taiwan share prices opened lower tuesday ||| dealers said.
In the experiments, we employ the popular NLP pipeline Stanford CoreNLP () to handle OpenIE and dependency parse at the same time. We combine the fact descriptions derived from both parts, and screen out the fact descriptions with the pattern "somebody said/declared/announced", which are usually meaningless: A dependency tree example. The meaning of the dependency labels can be referred to. We extract the following two fact descriptions: taiwan share prices opened lower tuesday ||| dealers said and insignificant. Referring to the copy ratios in, words in fact descriptions are 40% more likely to be used in the summary than the words in the original sentence. It indicates that fact descriptions truly condense the meaning of sentences to a large extent. The above statistics also supports the practice of dependency parse based compressive summarization (. However, the length sum of extracted fact descriptions is shorter than the actual summary in 20% of the sentences, and 4% of the sentences even hold empty fact descriptions. In addition, from we can find that on average one key source word is missing in the fact descriptions. Thus, without the source sentence, we cannot reply on fact descriptions alone to generate summaries.
Source: Sentence Fact AvgLen 31.4
18.2 Count 1 2.7 Copy% 0.12 0.17: Comparisons between source sentences and relations. AvgLen is the average number of tokens. Copy% means the proportion of source tokens can be found in the summary.
section: Fact Aware Neural Summarization
section: Model Framework
As shown in, our model consists of three modules including two encoders and a dual-attention decoder equipped with a context selection gate network. The sentence encoder reads the input words x = (x 1 , · · · x n ) and builds its corresponding representation (h x 1 , · · · h x n ). Likewise, the relation encoder converts the fact descriptions
With the respective attention mechanisms, our model computes the sentence and relation context vectors (c x t and c rt ) at each decoding time step t. The gate network is followed to merge the context vectors according to their relative associations with the current generation. The decoder produces summaries y = (y 1 , · · · y l ) word-by-word conditioned on the tailored context vector which embeds the semantics of both source sentence and fact descriptions.
section: Encoders
The input includes the source sentence x and the fact descriptions r. For each sequence, we employ the bidirectional Gated Recurrent Unit (BiGRU) encoder (), to construct its semantic representation. Take the sentence x as an example. The GRU at the time step i is defined as follows:
The BiGRU consists of a forward GRU and a backward GRU. Suppose the corresponding outputs are (
respectively. Then, the composite hidden state of a word is the concatenation of the two GRU repre-
For the relation sequence r, since it contains multiple independent fact descriptions, we introduce boundary indicators γ to separate their hidden states. Specially, the value of γ is defined as follows:
Then, γ is used to reset the GRU state in Eq. 1:
In this way, all the fact descriptions will start with the same zero vector. In other words, they are encoded independently. Finally, both sentence hidden states {h xi } and relation hidden states {h r i } are fed to the decoder.
section: Dual-Attention Decoder
Previous s2s models have developed some task-specific modifications on the decoder, such as to incorporate the copying mechanism () and coverage mechanism (See, Liu, and Manning 2017). As this paper focuses on the faithfulness problem, we use the most popular decoder, i.e., GRU with attentions (Bahdanau, Cho, and Bengio 2014). At each decoding time step t, GRU reads the previous output y t−1 and context vector c t−1 as inputs to compute new hidden state st :
Since we have both sentence and relation representations as input, we develop two attentional layers to construct the overall context vector ct . For instance, the context representation of the sentence at time step t is computed as (Luong, Pham, and Manning 2015):
í: Model framework where MLP stands for multi-layer perceptrons. The context vector of the relation c r can be computed similarly. We combine c x t and c rt to build the overall context vector ct . We explore two alternative combination approaches. The first one is called "FTSum c ", which simply concatenates two context vectors:
The other approach is denoted as "FTSum g ", where we also use MLP to build agate network and combine context vectors with the weighted sum:
where "" means the element-wise dot. Experiments show that FTSum g significantly outperforms FTSum c , and the gate values apparently reflect the relative reliability of sentence and fact descriptions. Finally, the softmax layer is introduced to generate the next word based on previous wordy t−1 , context vector ct and current decoder state st .
where W . stands fora weight matrix.
section: Learning
The learning goal is to maximize the estimated probability of the actual summary. We adopt the common negative loglikelihood (NLL) as the loss function.
where
section: Evaluation Metric
We adopt ROUGE (Lin 2004) for automatic evaluation. ROUGE has been the standard evaluation metric for DUC shared tasks since 2004. It measures the quality of summary by computing overlapping lexical units between the candidate summary and actual summaries, such as unigram, bigram and longest common subsequence (LCS). Following the common practice, we report ROUGE-1 (unigram), ROUGE-2 (bi-gram) and ROUGE-L (LCS) F1 scores 2 in the following experiments. ROUGE-1 and ROUGE-2 mainly consider informativeness while ROUGE-L is supposed to be linked to readability. In addition, we manually inspect whether the generated summaries accord with the facts in the original sentences. We mark summaries into three categories: FAITH-FUL, FAKE and UNCLEAR. The last one refers to the case where a generated summary is too incomplete to judge its faithfulness, such as just producing a UNK tag.
section: Implementation Details
Since the dataset has already masked infrequent words with the UNK tag, we reserve all the rest words in the training set. As a result, the sizes of source and target vocabularies are 120k and 69k, respectively. With reference to (), we leverage the popular s2s framework dl4mt as the starting point, and set the size of word embeddings to 200. We initialize word embeddings with GloVe. All the GRU hidden state dimensions are fixed to 400. We use dropout () with probability p = 0.5. With the decoder, we use the beam search of size 6 to generate the summary, and restrict the maximal length of a summary to 20 words. We find that the average system summary length from all our models (about 8.0 words) is very much consistent with that of the ground truth on the development set, without any special tuning.
section: Baselines
We compare our proposed model with the following six state-of-the-art baselines: ABS (Rush, Chopra, and Weston 2015a) used an attentive CNN encoder and NNLM decoder to summarize the sentence. ABS+ (Rush, Chopra, and Weston 2015a) further tuned the ABS model with additional features to balance the abstractive and extractive tendency. RAS-Elman As the extension of the ABS model, it used a convolutional attention-based encoder and an RNN decoder (). Feats2s () used a full s2s RNN model and added the hand-crafted features such as POS tag and NER, to enhance the encoder representation. Luong-NMT applied the two-layer LSTMs Neural machine translation model with 500 hidden units in each layer. att-s2s We implement the standard attentional s2s with dl4mt, and denote this baseline as "att-s2s".
section: Model
Perplexity ABS 27.1 RAS-Elman † 18.9 s2s-att 24.5 FTSum c 20.1 FTSum g 16.4
section: Informativeness Evaluation
At first, look at the final cost values during training in Table 5. We can see that our model achieves the lowest perplexity compared against the state-of-the-art systems. It is also noted that, FTSum g largely outperforms FTSum c , which verifies the importance of context selection. The ROUGE F1 scores are then reported in. Although the focus of our model focuses is to improve faithfulness, the ROUGE scores it receives are also much higher than the other methods. Note that, ABS+ and Feats2s have utilized a series of hand-crafted features, but our model is totally data-driven. Even though, our model surpasses Feats2s by 13% and ABS+ by 56% on ROUGE-2. When fact descriptions are ignored, our model is equivalent to the standard attentional s2s model s2s+att. Therefore, it is safe to conclude that, fact descriptions have significant contribute to the increase of ROUGE scores. One probable reason is that fact descriptions are much more informative than the original sentence, as shown in. It also largely explains why FTSum g is superior to FTSum c . FTSum c treats the source sentence and relations equally, while FTSum g tells the fact descriptions are often more reliable, as discussed in more detail later.
section: Faithfulness Evaluation
Next, we conduct manual evaluation to inspect the faithfulness of the generated summaries. Specially, we randomly select 100 sentences from the test set. Then, we classify the generated summaries as FAITHFUL, FAKE or UNCLEAR.
For the sake of a complete comparison, we present the results of our system FTSum g together with the the attentional s2s model s2s+att. As shown in: Faithfulness performance on the test set. s2s-att outputs gives disinformation. This number greatly reduces to 6% by our model. Nearly 90% of summaries generated by our model is faithful, which makes our model far more practical. We find that s2s-att tends to copy the words closer to the predicate and regard them as its subject and object. However, this is not always reasonable and thus it is actually counterfeiting messages. In comparison, the fact descriptions indeed designate the relations between a predicate and its subject and object. As a result, generation inline with the fact descriptions is usually able to keep the faithfulness.
We illustrate the examples of defective outputs in Table 8. As shown, att-s2s often attempts to fuse different parts in the source sentence to form the summary, no matter whether these phrases are relevant or not. For instance, atts2s treats "bosnian moslems" as the subject of "postponed" and "bosnia" as the object of "pulled out of" in Example 1. By contract, since the fact description point out the actual subject and object, the output of our model is faithful. In fact, it is exactly the same as the target summary. In Example 2, neither att-s2s nor our model achieves satisfactory performance. att-s2s again mismatches the object while our model fails to produce a complete sentence. To take a closer look, we find the target summary of this sentence is somewhat strange -it merely focuses on the prepositional phrase (after taking a ## stoke...), rather than the main clause as usual. Since the main clause is hard to summarize and there is no high-quality fact description extracted, our model fails to give a complete summary.
It is also noteworthy that, given multiple long fact descriptions, the generation of our model sometimes traps into one item. For instance, there are two long fact descriptions in Example 3 and our model only utilizes the first one for generation. As a result, despite the high faithfulness, the informativeness is somewhat damaged. Therefore, it seems more reliable to introduce the coverage mechanism (See, Liu, and Manning 2017) to handle the cases like this one. We leave it as our future work.
section: Gate Analysis
As shown in, FTSum g achieves much higher ROUGE scores than FTSum c . Now, we investigate what the gate network (Eq. 9) actually learns. The changes of the gate values on the development set during training are shown in. At the beginning, the average gate value exceeds 0.5, which means the generation is biased to the source sentence. As training proceeds, the model realizes that the fact descriptions are more reliable, resulting in a consecutive drop of the gate value. Finally, the average gate value is gradu- ally stabilized to 0.415. Interestingly, the ratio of sentence and relation gate values i.e., (1 − 0.415)/0.415 ≈ 1.41, is extremely close to the ratio of copying proportions shown in i.e., 0.17/0.12 ≈ 1.42. It seems that our model predicts the copy proportion and normalizes it as the gate value. Then, look at the standard deviation of gates. To our surprise, its change is nearly anti-symmetric to the mean value. The final standard deviation reaches about 90% of the mean gate value. Thus, still many sentences can dominate the generation. This strange observation urges us to carefully check the summaries with top/bottom-100 gate values in the development set. We find 10 fact descriptions in the top-100 cases are empty, and nearly 60% contains the UNK tag. Our model believes these fact descriptions have not much worth to guide generation. Instead, there is no empty fact descriptions and only 1 UNK tag in the bottom 100 cases. Hence these fact descriptions are usually informative enough. In addition, we find the instances with the lowest gate values often hold the following (target summary; fact description) pair:
Target COUNTRY share prices close/open #.# percent higher/lower
Fact COUNTRY share prices slumped/dropped/rose #.# percent
The extracted fact description itself is already a proper summary. That is why fact descriptions are particularly preferred in generation.
section: Related Work
Abstractive sentence summarization () aims to produce a shorter version of a given sentence while preserving its meaning. Unlike document-level summarization, it is impossible for this task to apply the common extractive techniques (e.g.,). Early studies for sentence summarization included rule-based methods (), syntactic tree pruning (Knight and Marcu 2002) and statistical machine translation techniques. Recently, the application of encoder-decoder structures has attracted growing attention in this area. proposed the ABS model which consisted of an attentive Convolutional Neural Network (CNN) Example 1 Source the repatriation of at least #,### bosnian moslems was postponed friday after the unhcr pulled out of the first joint scheme to return refugees to their homes in northwest bosnia . Relations unhcr pulled out of first joint scheme ||| repatriation was postponed friday ||| unhcr return refugees to their homes Target repatriation of bosnian moslems postponed att-s2s (FAKE) bosnian moslems postponed after unhcr pulled out of bosnia FTSum (FAITHFUL) repatriation of bosnian moslems postponed Example 2 Source davis love said he was thinking of making the world cup of golf a full time occupation after taking a ## stroke lead over japan in the event with us partner fred couples hereon saturday . Relations making world cup full time occupation ||| taking ## stroke lead Target americans lead UNK by ## strokes att-s2s (FAKE) davis love says he is thinking of the world cup FTSum (UNCLEAR) love in the world cup of golf Example 3 Source the us space shuttle atlantis separated from the orbiting russian mir space station early saturday , after three days of test runs for life in a future space facility , nasa announced . Relations us space shuttle atlantis separated from orbiting russian mir space station ||| us space shuttle atlantis runs after three days of test for line in future space facility Target atlantis mir part ways after three-day space collaboration by emmanuel UNK att-s2s
(UNCLEAR) space shuttle atlantis separated after # days of test runs for life FTSum (FAITHFUL) space shuttle atlantis separated from mir show that the above models achieve state-of-the-art performance.
In addition to the direct application of the general s2s framework, researchers attempted to import various properties of summarization. For example, () enriched the encoder with hand-crafted features such as named entities and POS tags. These features played important roles in traditional feature based summarization systems. ( found that a large proportion of words in the summary were copied from the source text. Therefore, they proposed CopyNet which considered the copying mechanism during generation. Later, () extended this work by directly measuring the copying mechanism within neural attentions. Meanwhile, they modified the decoder to reflect the rewriting behavior in summarization. Recently, (See, Liu, and Manning 2017) used the coverage mechanism to discourage repetition. There were also studies to modify the loss function to fit the evaluation metrics. For instance, (Ayana, Liu, and Sun 2016) applied Minimum Risk Training strategy to maximize the ROUGE scores of generated summaries. (Paulus, Xiong, and Socher 2017) used reinforcement learning algorithm to optimize a mixed objective function of likelihood and ROUGE scores.
Notably, previous researches usually focused on the improvement of summary informativeness. To the best of our knowledge, we are the first to explore the faithfulness problem of abstractive summarization.
section: Conclusion and Future Work
This paper investigates the faithfulness problem in abstractive summarization. We employ popular OpenIE and dependency parse tools to extract fact descriptions in the source sentence. Then, we propose the dual-attention s2s framework to force the generation conditioned on both source sentence and the fact descriptions. Experiments on the Gigaword benchmark demonstrate that our model greatly reduce fake summaries by 80%. In addition, since the fact descriptions often condense the meaning of the sentence, the import of them also brings significant improvement on informativeness.
We believe our work can be extended in various aspects. On the one hand, we plan to improve our decoder with the copying mechanism and coverage mechanism, which is further adapted to summarization. On the other hand, we are interested in the automatic evaluation of summary faithfulness.
